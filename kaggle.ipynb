{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e72e7933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 1: Loading full training data...\n",
      "\n",
      "Full Training Data Shape: (296209, 67)\n",
      "Rows: 296,209, Columns: 67\n",
      "        id  ps_ind_02_cat  ps_ind_04_cat  ps_ind_05_cat  ps_car_01_cat  \\\n",
      "0  1158448            1.0            1.0            0.0            7.0   \n",
      "1   341018            2.0            1.0            0.0            7.0   \n",
      "2   699143            2.0            0.0            0.0            4.0   \n",
      "3   744070            1.0            1.0            0.0            3.0   \n",
      "4   639390            2.0            0.0            0.0           11.0   \n",
      "\n",
      "   ps_car_02_cat  ps_car_03_cat  ps_car_04_cat  ps_car_05_cat  ps_car_06_cat  \\\n",
      "0            1.0            1.0              0            1.0             10   \n",
      "1            1.0            NaN              0            NaN             11   \n",
      "2            1.0            NaN              0            1.0              1   \n",
      "3            1.0            NaN              2            NaN              1   \n",
      "4            1.0            NaN              2            NaN             11   \n",
      "\n",
      "   ...  ps_calc_20_bin  feature1  feature2  feature3  feature4  feature5  \\\n",
      "0  ...               0         0  4.136926         3  0.777766        25   \n",
      "1  ...               0         0  0.592341         3  0.770527         1   \n",
      "2  ...               0         0  0.950207         6  0.757445         4   \n",
      "3  ...               1         0  2.013771         5       NaN         4   \n",
      "4  ...               0         0  0.000000         3  0.767450         0   \n",
      "\n",
      "        feature6  feature7  feature8  target  \n",
      "0       0.165477  3.010493        16       0  \n",
      "1       0.592340  3.036803        16       0  \n",
      "2       0.237552  2.536030        16       0  \n",
      "3       0.503442  3.251724        15       0  \n",
      "4  793360.881100  2.703617        18       1  \n",
      "\n",
      "[5 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    " \n",
    "ERP_ID = 123456  # REPLACE WITH YOUR ACTUAL ERP ID\n",
    "RANDOM_STATE = ERP_ID\n",
    " \n",
    " \n",
    "print(\"\\nSTEP 1: Loading full training data...\")\n",
    "\n",
    "# Load complete training data\n",
    "train = pd.read_csv('train1.csv')\n",
    "\n",
    "print(f\"\\nFull Training Data Shape: {train.shape}\")\n",
    "print(f\"Rows: {train.shape[0]:,}, Columns: {train.shape[1]}\")\n",
    "\n",
    "\n",
    "print(train.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6e445ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target distribution:\n",
      "target\n",
      "0    281023\n",
      "1     15186\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target proportions:\n",
      "target\n",
      "0    0.948732\n",
      "1    0.051268\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class imbalance ratio: 18.51:1\n",
      "‚ö†Ô∏è  Dataset is imbalanced - consider class_weight='balanced'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if 'target' in train.columns:\n",
    "    target_col = 'target'\n",
    "elif 'label' in train.columns:\n",
    "    target_col = 'label'\n",
    "else:\n",
    "    # Assume last column is target\n",
    "    target_col = train.columns[-1]\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(train[target_col].value_counts())\n",
    "print(\"\\nTarget proportions:\")\n",
    "print(train[target_col].value_counts(normalize=True))\n",
    "\n",
    "# Check class imbalance\n",
    "class_counts = train[target_col].value_counts()\n",
    "imbalance_ratio = class_counts.max() / class_counts.min()\n",
    "print(f\"\\nClass imbalance ratio: {imbalance_ratio:.2f}:1\")\n",
    "\n",
    "if imbalance_ratio > 2:\n",
    "    print(\"‚ö†Ô∏è  Dataset is imbalanced - consider class_weight='balanced'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5363aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= train.drop('target', axis=1)\n",
    "y= train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5ff2a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Missing Value Percentages ===\n",
      "           Column  Missing_Count  Missing_Percentage\n",
      "6   ps_car_03_cat         204589           69.069137\n",
      "8   ps_car_05_cat         132287           44.660020\n",
      "32      ps_reg_03          53579           18.088242\n",
      "61       feature4          53579           18.088242\n",
      "36      ps_car_14          21108            7.126050\n",
      "10  ps_car_07_cat           5783            1.952338\n",
      "3   ps_ind_05_cat           2915            0.984102\n",
      "12  ps_car_09_cat            288            0.097229\n",
      "1   ps_ind_02_cat            125            0.042200\n",
      "4   ps_car_01_cat             57            0.019243\n",
      "2   ps_ind_04_cat             45            0.015192\n",
      "33      ps_car_11              4            0.001350\n",
      "5   ps_car_02_cat              3            0.001013\n",
      "34      ps_car_12              1            0.000338\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Missing Value Percentages ===\")\n",
    "missing = X.isnull().sum()\n",
    "missing_pct = (missing / len(X)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing.index,\n",
    "    'Missing_Count': missing.values,\n",
    "    'Missing_Percentage': missing_pct.values\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ab8a9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['id', 'feature1', 'feature7'] ['ps_car_03_cat', 'ps_car_05_cat']\n"
     ]
    }
   ],
   "source": [
    "cols_to_drop_train = ['id', 'feature1', 'feature7']\n",
    "X = X.drop(columns=cols_to_drop_train, errors='ignore')\n",
    "high_missing_train = ['ps_car_03_cat', 'ps_car_05_cat']\n",
    "X = X.drop(columns=high_missing_train, errors='ignore')\n",
    "print(\"Dropped columns:\", cols_to_drop_train, high_missing_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbd96f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Missing values handled successfully!\n",
      "Categorical columns: 12, bins columns: 17, Numeric columns: 32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# 1Ô∏è‚É£ Identify categorical and numeric columns based on pattern\n",
    "cat_cols = [col for col in X.columns if '_cat' in col ]\n",
    "cat_cols_bins = [col for col in X.columns if '_bin' in col]\n",
    "num_cols = [col for col in X.columns if col not in cat_cols and col not in cat_cols_bins and col != 'target']\n",
    "\n",
    "\n",
    "# 2Ô∏è‚É£ Create imputers\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "cat_bins_imputer = SimpleImputer(strategy='most_frequent')\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# 3Ô∏è‚É£ Apply imputations on training data\n",
    "X[cat_cols] = cat_imputer.fit_transform(X[cat_cols])\n",
    "X[cat_cols_bins] = cat_bins_imputer.fit_transform(X[cat_cols_bins])\n",
    "X[num_cols] = num_imputer.fit_transform(X[num_cols])\n",
    "\n",
    "\n",
    "print(\"‚úÖ Missing values handled successfully!\")\n",
    "print(f\"Categorical columns: {len(cat_cols)}, bins columns: {len(cat_cols_bins)}, Numeric columns: {len(num_cols)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6492ee62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Missing values in final X: 0\n",
      "‚úÖ Final shape: (296209, 220)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# üîπ Encode Categorical Variables\n",
    "# ============================================================================\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 3Ô∏è‚É£ Encode categorical columns\n",
    "#handle_unknown='use_encoded_value', unknown_value=-1\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded_train = pd.DataFrame(\n",
    "    encoder.fit_transform(X[cat_cols]),\n",
    "    columns=encoder.get_feature_names_out(cat_cols),\n",
    "    index=X.index\n",
    ")\n",
    "\n",
    "# 4Ô∏è‚É£ Merge encoded, numeric, binary, and target columns\n",
    "X_train_final = pd.concat(\n",
    "    [encoded_train, X[num_cols], X[cat_cols_bins]],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# üß© Final check\n",
    "print(\"‚úÖ Missing values in final X:\", X_train_final.isnull().sum().sum())\n",
    "print(\"‚úÖ Final shape:\", X_train_final.shape)\n",
    "\n",
    "# 5Ô∏è‚É£ Optional: Split into X and y\n",
    "\n",
    "# X2 and y2 are for encoding data\n",
    "X2 = X_train_final\n",
    "y2= y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "945b4175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Separating features and target...\n",
      "\n",
      "Feature matrix (X_full): (296209, 220)\n",
      "Target vector (y_full): (296209,)\n",
      "Total features: 220\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SEPARATE FEATURES AND TARGET\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Separating features and target...\")\n",
    "\n",
    "# Remove ID and target from features\n",
    "feature_cols = [col for col in X2.columns \n",
    "                if col != target_col and col != 'id']\n",
    "\n",
    "X_full = X2[feature_cols]\n",
    "y_full = y\n",
    "\n",
    "print(f\"\\nFeature matrix (X_full): {X_full.shape}\")\n",
    "print(f\"Target vector (y_full): {y_full.shape}\")\n",
    "print(f\"Total features: {X_full.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19bcec90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Scaling features (for distance-based models)...\n",
      "‚úì Features scaled using StandardScaler\n",
      "\n",
      "‚úì Preprocessing complete!\n",
      "‚úì Ready for model training on 100% of data\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Scaling features (for distance-based models)...\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_full_scaled = scaler.fit_transform(X_full)\n",
    "\n",
    "print(\"‚úì Features scaled using StandardScaler\")\n",
    "\n",
    "# Convert back to DataFrame for easier handling\n",
    "X_full_scaled_df = pd.DataFrame(X_full_scaled, columns=feature_cols, index=X_full.index)\n",
    "\n",
    "print(\"\\n‚úì Preprocessing complete!\")\n",
    "print(\"‚úì Ready for model training on 100% of data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66b19c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL 1: CATEGORICAL NAIVE BAYES\n",
      "================================================================================\n",
      "\n",
      "Note: CategoricalNB requires non-negative integer features\n",
      "Converting features to non-negative integers...\n",
      "‚úì Features converted\n",
      "\n",
      "Training Categorical Naive Bayes on full dataset...\n",
      "Training samples: 296,209\n",
      "‚úì Training completed in 1.86 seconds\n",
      "\n",
      "Training set performance:\n",
      "  AUROC: 0.6423\n",
      "  Accuracy: 0.9461\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97    281023\n",
      "           1       0.23      0.02      0.04     15186\n",
      "\n",
      "    accuracy                           0.95    296209\n",
      "   macro avg       0.59      0.51      0.51    296209\n",
      "weighted avg       0.91      0.95      0.92    296209\n",
      "\n",
      "\n",
      "‚úì Categorical Naive Bayes training complete!\n",
      "‚úì Model ready for test predictions\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "import time\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL 1: CATEGORICAL NAIVE BAYES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL 1: CATEGORICAL NAIVE BAYES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nNote: CategoricalNB requires non-negative integer features\")\n",
    "print(\"Converting features to non-negative integers...\")\n",
    "\n",
    "# Ensure all features are non-negative (shift if needed)\n",
    "X_full_nb = X_full.copy()\n",
    "\n",
    "for col in X_full_nb.columns:\n",
    "    min_val = X_full_nb[col].min()\n",
    "    if min_val < 0:\n",
    "        X_full_nb[col] = X_full_nb[col] - min_val\n",
    "\n",
    "# Convert to integers\n",
    "X_full_nb = X_full_nb.astype(int)\n",
    "\n",
    "print(\"‚úì Features converted\")\n",
    "\n",
    "# Train model on 100% of data\n",
    "print(\"\\nTraining Categorical Naive Bayes on full dataset...\")\n",
    "print(f\"Training samples: {X_full_nb.shape[0]:,}\")\n",
    "start_time = time.time()\n",
    "\n",
    "nb_model = CategoricalNB(alpha=1.0)  # Laplace smoothing\n",
    "nb_model.fit(X_full_nb, y_full)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"‚úì Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "# Training set performance (for reference only)\n",
    "print(\"\\nTraining set performance:\")\n",
    "y_train_pred_nb = nb_model.predict(X_full_nb)\n",
    "y_train_proba_nb = nb_model.predict_proba(X_full_nb)[:, 1]\n",
    "\n",
    "train_auroc_nb = roc_auc_score(y_full, y_train_proba_nb)\n",
    "train_acc_nb = accuracy_score(y_full, y_train_pred_nb)\n",
    "\n",
    "print(f\"  AUROC: {train_auroc_nb:.4f}\")\n",
    "print(f\"  Accuracy: {train_acc_nb:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_full, y_train_pred_nb))\n",
    "\n",
    "# Store results\n",
    "results = {\n",
    "    'Model': [],\n",
    "    'Train_AUROC': [],\n",
    "    'Train_Acc': [],\n",
    "    'Training_Time': [],\n",
    "    'Model_Object': []\n",
    "}\n",
    "\n",
    "results['Model'].append('Categorical Naive Bayes')\n",
    "results['Train_AUROC'].append(train_auroc_nb)\n",
    "results['Train_Acc'].append(train_acc_nb)\n",
    "results['Training_Time'].append(training_time)\n",
    "results['Model_Object'].append(('nb', nb_model, X_full_nb))  # Store for later use\n",
    "\n",
    "print(\"\\n‚úì Categorical Naive Bayes training complete!\")\n",
    "print(\"‚úì Model ready for test predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9cc21a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL 2: K-NEAREST NEIGHBORS (KNN)\n",
      "================================================================================\n",
      "\n",
      "Note: KNN uses scaled features for better performance\n",
      "Training samples: 296,209\n",
      "\n",
      "Training KNN with k=5...\n",
      "‚úì Training completed in 4.21 seconds\n",
      "\n",
      "Training set performance:\n",
      "  AUROC: 0.9240\n",
      "  Accuracy: 0.9491\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97    281023\n",
      "           1       0.62      0.02      0.04     15186\n",
      "\n",
      "    accuracy                           0.95    296209\n",
      "   macro avg       0.78      0.51      0.51    296209\n",
      "weighted avg       0.93      0.95      0.93    296209\n",
      "\n",
      "\n",
      "‚úì KNN training complete!\n",
      "‚úì Model ready for test predictions\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL 2: K-NEAREST NEIGHBORS (KNN)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL 2: K-NEAREST NEIGHBORS (KNN)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nNote: KNN uses scaled features for better performance\")\n",
    "print(f\"Training samples: {X_full_scaled.shape[0]:,}\")\n",
    "\n",
    "# Train model with k=5\n",
    "print(\"\\nTraining KNN with k=5...\")\n",
    "start_time = time.time()\n",
    "\n",
    "knn_model = KNeighborsClassifier(\n",
    "    n_neighbors=5,\n",
    "    weights='uniform',\n",
    "    metric='euclidean',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "knn_model.fit(X_full_scaled, y_full)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"‚úì Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "# Training set performance (for reference only)\n",
    "print(\"\\nTraining set performance:\")\n",
    "y_train_pred_knn = knn_model.predict(X_full_scaled)\n",
    "y_train_proba_knn = knn_model.predict_proba(X_full_scaled)[:, 1]\n",
    "\n",
    "train_auroc_knn = roc_auc_score(y_full, y_train_proba_knn)\n",
    "train_acc_knn = accuracy_score(y_full, y_train_pred_knn)\n",
    "\n",
    "print(f\"  AUROC: {train_auroc_knn:.4f}\")\n",
    "print(f\"  Accuracy: {train_acc_knn:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_full, y_train_pred_knn))\n",
    "\n",
    "# Store results\n",
    "results['Model'].append('K-Nearest Neighbors (k=5)')\n",
    "results['Train_AUROC'].append(train_auroc_knn)\n",
    "results['Train_Acc'].append(train_acc_knn)\n",
    "results['Training_Time'].append(training_time)\n",
    "results['Model_Object'].append(('knn', knn_model, X_full_scaled))\n",
    "\n",
    "print(\"\\n‚úì KNN training complete!\")\n",
    "print(\"‚úì Model ready for test predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b2ac940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL 3: DECISION TREE\n",
      "================================================================================\n",
      "Training samples: 296,209\n",
      "\n",
      "Training Decision Tree...\n",
      "‚úì Training completed in 12.50 seconds\n",
      "\n",
      "Model structure:\n",
      "  Tree depth: 10\n",
      "  Number of leaves: 512\n",
      "  Number of nodes: 1023\n",
      "\n",
      "Training set performance:\n",
      "  AUROC: 0.6743\n",
      "  Accuracy: 0.6820\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.69      0.80    281023\n",
      "           1       0.09      0.55      0.15     15186\n",
      "\n",
      "    accuracy                           0.68    296209\n",
      "   macro avg       0.53      0.62      0.48    296209\n",
      "weighted avg       0.92      0.68      0.77    296209\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Top 10 Important Features:\n",
      "  ps_car_13                     : 0.2022\n",
      "  ps_ind_17_bin                 : 0.0688\n",
      "  ps_ind_03                     : 0.0541\n",
      "  ps_reg_03                     : 0.0506\n",
      "  ps_ind_05_cat_0.0             : 0.0473\n",
      "  ps_reg_02                     : 0.0456\n",
      "  ps_car_14                     : 0.0432\n",
      "  feature4                      : 0.0415\n",
      "  ps_ind_15                     : 0.0377\n",
      "  feature6                      : 0.0305\n",
      "\n",
      "‚úì Decision Tree training complete!\n",
      "‚úì Model ready for test predictions\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL 3: DECISION TREE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL 3: DECISION TREE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"Training samples: {X_full.shape[0]:,}\")\n",
    "\n",
    "# Train model with good default parameters\n",
    "print(\"\\nTraining Decision Tree...\")\n",
    "start_time = time.time()\n",
    "\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10,\n",
    "    class_weight='balanced',  # Handle imbalance\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "dt_model.fit(X_full, y_full)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"‚úì Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "# Model info\n",
    "print(f\"\\nModel structure:\")\n",
    "print(f\"  Tree depth: {dt_model.get_depth()}\")\n",
    "print(f\"  Number of leaves: {dt_model.get_n_leaves()}\")\n",
    "print(f\"  Number of nodes: {dt_model.tree_.node_count}\")\n",
    "\n",
    "# Training set performance (for reference only)\n",
    "print(\"\\nTraining set performance:\")\n",
    "y_train_pred_dt = dt_model.predict(X_full)\n",
    "y_train_proba_dt = dt_model.predict_proba(X_full)[:, 1]\n",
    "\n",
    "train_auroc_dt = roc_auc_score(y_full, y_train_proba_dt)\n",
    "train_acc_dt = accuracy_score(y_full, y_train_pred_dt)\n",
    "\n",
    "print(f\"  AUROC: {train_auroc_dt:.4f}\")\n",
    "print(f\"  Accuracy: {train_acc_dt:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_full, y_train_pred_dt))\n",
    "\n",
    "# Feature importance\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Top 10 Important Features:\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_full.columns,\n",
    "    'Importance': dt_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "for i, row in feature_importance.head(10).iterrows():\n",
    "    print(f\"  {row['Feature']:30s}: {row['Importance']:.4f}\")\n",
    "\n",
    "# Store results\n",
    "results['Model'].append('Decision Tree')\n",
    "results['Train_AUROC'].append(train_auroc_dt)\n",
    "results['Train_Acc'].append(train_acc_dt)\n",
    "results['Training_Time'].append(training_time)\n",
    "results['Model_Object'].append(('dt', dt_model, X_full))\n",
    "\n",
    "print(\"\\n‚úì Decision Tree training complete!\")\n",
    "print(\"‚úì Model ready for test predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98170662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL 4: RANDOM FOREST\n",
      "================================================================================\n",
      "Training samples: 296,209\n",
      "\n",
      "Training Random Forest with 100 trees...\n",
      "‚úì Training completed in 48.85 seconds\n",
      "\n",
      "Model info:\n",
      "  Number of trees: 100\n",
      "  Max depth: 15\n",
      "\n",
      "Training set performance:\n",
      "  AUROC: 0.9116\n",
      "  Accuracy: 0.9331\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96    281023\n",
      "           1       0.41      0.66      0.50     15186\n",
      "\n",
      "    accuracy                           0.93    296209\n",
      "   macro avg       0.69      0.80      0.73    296209\n",
      "weighted avg       0.95      0.93      0.94    296209\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Top 10 Important Features:\n",
      "  ps_car_13                     : 0.0566\n",
      "  ps_reg_03                     : 0.0413\n",
      "  feature4                      : 0.0402\n",
      "  feature6                      : 0.0392\n",
      "  feature2                      : 0.0330\n",
      "  ps_car_14                     : 0.0326\n",
      "  ps_reg_02                     : 0.0307\n",
      "  ps_ind_15                     : 0.0296\n",
      "  ps_ind_03                     : 0.0286\n",
      "  ps_car_15                     : 0.0248\n",
      "\n",
      "‚úì Random Forest training complete!\n",
      "‚úì Model ready for test predictions\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL 4: RANDOM FOREST\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL 4: RANDOM FOREST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"Training samples: {X_full.shape[0]:,}\")\n",
    "\n",
    "# Train model\n",
    "print(\"\\nTraining Random Forest with 100 trees...\")\n",
    "start_time = time.time()\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "rf_model.fit(X_full, y_full)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"‚úì Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "print(f\"\\nModel info:\")\n",
    "print(f\"  Number of trees: {rf_model.n_estimators}\")\n",
    "print(f\"  Max depth: {rf_model.max_depth}\")\n",
    "\n",
    "# Training set performance (for reference only)\n",
    "print(\"\\nTraining set performance:\")\n",
    "y_train_pred_rf = rf_model.predict(X_full)\n",
    "y_train_proba_rf = rf_model.predict_proba(X_full)[:, 1]\n",
    "\n",
    "train_auroc_rf = roc_auc_score(y_full, y_train_proba_rf)\n",
    "train_acc_rf = accuracy_score(y_full, y_train_pred_rf)\n",
    "\n",
    "print(f\"  AUROC: {train_auroc_rf:.4f}\")\n",
    "print(f\"  Accuracy: {train_acc_rf:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_full, y_train_pred_rf))\n",
    "\n",
    "# Feature importance\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Top 10 Important Features:\")\n",
    "feature_importance_rf = pd.DataFrame({\n",
    "    'Feature': X_full.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "for i, row in feature_importance_rf.head(10).iterrows():\n",
    "    print(f\"  {row['Feature']:30s}: {row['Importance']:.4f}\")\n",
    "\n",
    "# Store results\n",
    "results['Model'].append('Random Forest')\n",
    "results['Train_AUROC'].append(train_auroc_rf)\n",
    "results['Train_Acc'].append(train_acc_rf)\n",
    "results['Training_Time'].append(training_time)\n",
    "results['Model_Object'].append(('rf', rf_model, X_full))\n",
    "\n",
    "print(\"\\n‚úì Random Forest training complete!\")\n",
    "print(\"‚úì Model ready for test predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "adaad980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL 5: ADABOOST\n",
      "================================================================================\n",
      "Training samples: 296,209\n",
      "\n",
      "Training AdaBoost with 100 estimators...\n",
      "‚úì Training completed in 341.44 seconds\n",
      "\n",
      "Model info:\n",
      "  Number of estimators: 100\n",
      "  Learning rate: 1.0\n",
      "\n",
      "Training set performance:\n",
      "  AUROC: 0.6438\n",
      "  Accuracy: 0.9487\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97    281023\n",
      "           1       0.00      0.00      0.00     15186\n",
      "\n",
      "    accuracy                           0.95    296209\n",
      "   macro avg       0.47      0.50      0.49    296209\n",
      "weighted avg       0.90      0.95      0.92    296209\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Top 10 Important Features:\n",
      "  ps_car_13                     : 0.2718\n",
      "  ps_ind_17_bin                 : 0.1529\n",
      "  ps_ind_05_cat_0.0             : 0.0996\n",
      "  ps_ind_03                     : 0.0774\n",
      "  ps_reg_02                     : 0.0606\n",
      "  feature6                      : 0.0254\n",
      "  ps_calc_09                    : 0.0237\n",
      "  ps_reg_03                     : 0.0224\n",
      "  feature4                      : 0.0201\n",
      "  ps_reg_01                     : 0.0185\n",
      "\n",
      "‚úì AdaBoost training complete!\n",
      "‚úì Model ready for test predictions\n"
     ]
    }
   ],
   "source": [
    " \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL 5: ADABOOST\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL 5: ADABOOST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"Training samples: {X_full.shape[0]:,}\")\n",
    "\n",
    "# Train model\n",
    "print(\"\\nTraining AdaBoost with 100 estimators...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Use Decision Tree as base estimator\n",
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=3,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "ada_model = AdaBoostClassifier(\n",
    "    estimator=base_estimator,\n",
    "    n_estimators=100,\n",
    "    learning_rate=1.0,\n",
    "    algorithm='SAMME',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "ada_model.fit(X_full, y_full)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"‚úì Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "print(f\"\\nModel info:\")\n",
    "print(f\"  Number of estimators: {ada_model.n_estimators}\")\n",
    "print(f\"  Learning rate: {ada_model.learning_rate}\")\n",
    "\n",
    "# Training set performance (for reference only)\n",
    "print(\"\\nTraining set performance:\")\n",
    "y_train_pred_ada = ada_model.predict(X_full)\n",
    "y_train_proba_ada = ada_model.predict_proba(X_full)[:, 1]\n",
    "\n",
    "train_auroc_ada = roc_auc_score(y_full, y_train_proba_ada)\n",
    "train_acc_ada = accuracy_score(y_full, y_train_pred_ada)\n",
    "\n",
    "print(f\"  AUROC: {train_auroc_ada:.4f}\")\n",
    "print(f\"  Accuracy: {train_acc_ada:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_full, y_train_pred_ada))\n",
    "\n",
    "# Feature importance (if available)\n",
    "if hasattr(ada_model, 'feature_importances_'):\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Top 10 Important Features:\")\n",
    "    feature_importance_ada = pd.DataFrame({\n",
    "        'Feature': X_full.columns,\n",
    "        'Importance': ada_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    for i, row in feature_importance_ada.head(10).iterrows():\n",
    "        print(f\"  {row['Feature']:30s}: {row['Importance']:.4f}\")\n",
    "\n",
    "# Store results\n",
    "results['Model'].append('AdaBoost')\n",
    "results['Train_AUROC'].append(train_auroc_ada)\n",
    "results['Train_Acc'].append(train_acc_ada)\n",
    "results['Training_Time'].append(training_time)\n",
    "results['Model_Object'].append(('ada', ada_model, X_full))\n",
    "\n",
    "print(\"\\n‚úì AdaBoost training complete!\")\n",
    "print(\"‚úì Model ready for test predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bc3a5779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TRAINING PERFORMANCE COMPARISON\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Note: These are training metrics only.\n",
      "True performance will be evaluated on Kaggle test set.\n",
      "\n",
      "                    Model  Train_AUROC  Train_Acc  Training_Time\n",
      "K-Nearest Neighbors (k=5)     0.923991   0.949100       4.213133\n",
      "            Random Forest     0.911605   0.933098      48.851928\n",
      "            Decision Tree     0.674326   0.681981      12.497012\n",
      "                 AdaBoost     0.643753   0.948732     341.440990\n",
      "  Categorical Naive Bayes     0.642263   0.946150       1.863915\n",
      "\n",
      "‚ö†Ô∏è  WARNING: Training AUROC may not reflect generalization!\n",
      "   Models with high training AUROC may overfit.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Creating comparison visualizations...\n",
      "‚úì Saved 'model_training_comparison.png'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL CHARACTERISTICS & EXPECTATIONS\n",
      "================================================================================\n",
      "\n",
      "1. CATEGORICAL NAIVE BAYES:\n",
      "   Expected: Fast, good with categorical features\n",
      "   Risk: Assumes independence, may underperform\n",
      "\n",
      "2. K-NEAREST NEIGHBORS:\n",
      "   Expected: Can overfit training data (memorization)\n",
      "   Risk: Very high training AUROC, slower on test\n",
      "\n",
      "3. DECISION TREE:\n",
      "   Expected: May overfit without proper pruning\n",
      "   Risk: High training AUROC, lower test AUROC\n",
      "\n",
      "4. RANDOM FOREST:\n",
      "   Expected: Good balance, reduced overfitting\n",
      "   Strength: Generally strong generalization\n",
      "\n",
      "5. ADABOOST:\n",
      "   Expected: Focuses on hard samples\n",
      "   Strength: Good with imbalanced data\n",
      "\n",
      "================================================================================\n",
      "MODEL SELECTION FOR SUBMISSION\n",
      "================================================================================\n",
      "\n",
      "Recommendation based on characteristics:\n",
      "  1st choice: Random Forest (best generalization)\n",
      "  2nd choice: AdaBoost (handles imbalance)\n",
      "  3rd choice: Decision Tree (if you want interpretability)\n",
      "\n",
      "You should submit predictions from ALL 5 models to Kaggle\n",
      "and see which performs best on the public leaderboard!\n",
      "\n",
      "‚úì Results saved to 'model_training_comparison.csv'\n",
      "\n",
      "‚úì Model comparison complete!\n",
      "‚úì Ready to generate test predictions for all models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE COMPARISON TABLE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Remove Model_Object before creating DataFrame\n",
    "results_comparison = {k: v for k, v in results.items() if k != 'Model_Object'}\n",
    "results_df = pd.DataFrame(results_comparison)\n",
    "results_df = results_df.sort_values('Train_AUROC', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"TRAINING PERFORMANCE COMPARISON\")\n",
    "print(\"-\"*80)\n",
    "print(\"\\nNote: These are training metrics only.\")\n",
    "print(\"True performance will be evaluated on Kaggle test set.\\n\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  WARNING: Training AUROC may not reflect generalization!\")\n",
    "print(\"   Models with high training AUROC may overfit.\")\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZE COMPARISON\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Creating comparison visualizations...\")\n",
    "\n",
    "# Plot: Training metrics comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# AUROC comparison\n",
    "ax1 = axes[0]\n",
    "x_pos = np.arange(len(results_df))\n",
    "ax1.barh(x_pos, results_df['Train_AUROC'], alpha=0.7, color='steelblue')\n",
    "ax1.set_yticks(x_pos)\n",
    "ax1.set_yticklabels(results_df['Model'])\n",
    "ax1.set_xlabel('Training AUROC')\n",
    "ax1.set_title('Model Training AUROC Comparison')\n",
    "ax1.invert_yaxis()\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add values on bars\n",
    "for i, v in enumerate(results_df['Train_AUROC']):\n",
    "    ax1.text(v + 0.005, i, f'{v:.8f}', va='center')\n",
    "\n",
    "# Accuracy comparison\n",
    "ax2 = axes[1]\n",
    "ax2.barh(x_pos, results_df['Train_Acc'], alpha=0.7, color='coral')\n",
    "ax2.set_yticks(x_pos)\n",
    "ax2.set_yticklabels(results_df['Model'])\n",
    "ax2.set_xlabel('Training Accuracy')\n",
    "ax2.set_title('Model Training Accuracy Comparison')\n",
    "ax2.invert_yaxis()\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Training time comparison\n",
    "ax3 = axes[2]\n",
    "ax3.barh(x_pos, results_df['Training_Time'], alpha=0.7, color='lightgreen')\n",
    "ax3.set_yticks(x_pos)\n",
    "ax3.set_yticklabels(results_df['Model'])\n",
    "ax3.set_xlabel('Training Time (seconds)')\n",
    "ax3.set_title('Training Time Comparison')\n",
    "ax3.invert_yaxis()\n",
    "ax3.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_training_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì Saved 'model_training_comparison.png'\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL CHARACTERISTICS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL CHARACTERISTICS & EXPECTATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. CATEGORICAL NAIVE BAYES:\")\n",
    "print(\"   Expected: Fast, good with categorical features\")\n",
    "print(\"   Risk: Assumes independence, may underperform\")\n",
    "\n",
    "print(\"\\n2. K-NEAREST NEIGHBORS:\")\n",
    "print(\"   Expected: Can overfit training data (memorization)\")\n",
    "print(\"   Risk: Very high training AUROC, slower on test\")\n",
    "\n",
    "print(\"\\n3. DECISION TREE:\")\n",
    "print(\"   Expected: May overfit without proper pruning\")\n",
    "print(\"   Risk: High training AUROC, lower test AUROC\")\n",
    "\n",
    "print(\"\\n4. RANDOM FOREST:\")\n",
    "print(\"   Expected: Good balance, reduced overfitting\")\n",
    "print(\"   Strength: Generally strong generalization\")\n",
    "\n",
    "print(\"\\n5. ADABOOST:\")\n",
    "print(\"   Expected: Focuses on hard samples\")\n",
    "print(\"   Strength: Good with imbalanced data\")\n",
    "\n",
    "# ============================================================================\n",
    "# IDENTIFY BEST MODEL FOR SUBMISSION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL SELECTION FOR SUBMISSION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Heuristic: Choose Random Forest or AdaBoost (better generalization)\n",
    "# Unless training metrics strongly suggest otherwise\n",
    "\n",
    "print(\"\\nRecommendation based on characteristics:\")\n",
    "print(\"  1st choice: Random Forest (best generalization)\")\n",
    "print(\"  2nd choice: AdaBoost (handles imbalance)\")\n",
    "print(\"  3rd choice: Decision Tree (if you want interpretability)\")\n",
    "\n",
    "print(\"\\nYou should submit predictions from ALL 5 models to Kaggle\")\n",
    "print(\"and see which performs best on the public leaderboard!\")\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('model_training_comparison.csv', index=False)\n",
    "print(\"\\n‚úì Results saved to 'model_training_comparison.csv'\")\n",
    "\n",
    "print(\"\\n‚úì Model comparison complete!\")\n",
    "print(\"‚úì Ready to generate test predictions for all models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "378565cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GENERATING TEST SET PREDICTIONS FOR ALL MODELS\n",
      "================================================================================\n",
      "\n",
      "Loading test.csv...\n",
      "Test set shape: (126948, 66)\n",
      "Test samples: 126,948\n",
      "\n",
      "First 5 rows:\n",
      "       id  ps_ind_02_cat  ps_ind_04_cat  ps_ind_05_cat  ps_car_01_cat  \\\n",
      "0  722071            1.0            0.0            0.0            7.0   \n",
      "1  114307            1.0            0.0            0.0            8.0   \n",
      "2   17470            1.0            1.0            0.0            9.0   \n",
      "3  660658            4.0            1.0            0.0           11.0   \n",
      "4  813204            3.0            1.0            0.0           11.0   \n",
      "\n",
      "   ps_car_02_cat  ps_car_03_cat  ps_car_04_cat  ps_car_05_cat  ps_car_06_cat  \\\n",
      "0            1.0            1.0              0            1.0             11   \n",
      "1            0.0            NaN              9            1.0              9   \n",
      "2            0.0            1.0              0            0.0             11   \n",
      "3            1.0            NaN              0            NaN              0   \n",
      "4            0.0            NaN              0            NaN             10   \n",
      "\n",
      "   ...  ps_calc_19_bin  ps_calc_20_bin  feature1  feature2  feature3  \\\n",
      "0  ...               0               0         0  3.531514         4   \n",
      "1  ...               0               0         0  2.516425         4   \n",
      "2  ...               1               0         0  1.850240         6   \n",
      "3  ...               0               1         0  4.111878         4   \n",
      "4  ...               0               1         0  0.669772         5   \n",
      "\n",
      "   feature4  feature5  feature6  feature7  feature8  \n",
      "0  0.784260        25  0.141261  3.037129        15  \n",
      "1  0.896610         4  0.629106  2.684624        16  \n",
      "2  1.288607         4  0.462560  2.340995        13  \n",
      "3  0.918916        25  0.164475  3.255859        15  \n",
      "4  0.838150         1  0.669772  2.764241        13  \n",
      "\n",
      "[5 rows x 66 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATING TEST SET PREDICTIONS FOR ALL MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nLoading test.csv...\")\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "print(f\"Test set shape: {test.shape}\")\n",
    "print(f\"Test samples: {test.shape[0]:,}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d32f6a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Found 126948 test IDs\n"
     ]
    }
   ],
   "source": [
    "id_col = 'id'\n",
    "\n",
    "if id_col in test.columns:\n",
    "    test_ids = test[id_col].copy()\n",
    "    print(f\"\\n‚úì Found {len(test_ids)} test IDs\")\n",
    "else:\n",
    "    test_ids = pd.Series(range(len(test)), name='id')\n",
    "    print(\"\\n‚ö†Ô∏è  No ID column found, using sequential IDs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "434db56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Preprocessing test data...\n",
      "Test data after removing ID: (126948, 65)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Preprocessing test data...\")\n",
    "\n",
    " \n",
    "\n",
    "X_test_df = test.copy()\n",
    "\n",
    "# Remove ID column\n",
    "if id_col in X_test_df.columns:\n",
    "    X_test_df = X_test_df.drop(columns=[id_col])\n",
    "\n",
    "print(f\"Test data after removing ID: {X_test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77645bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Dropping same columns as training...\n",
      "‚úì Dropped columns: ['feature1', 'feature7', 'ps_car_03_cat', 'ps_car_05_cat']\n",
      "Test data shape after dropping: (126948, 61)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Dropping same columns as training...\")\n",
    "\n",
    "# Drop same columns as you did in training\n",
    "cols_to_drop_test = ['feature1', 'feature7']  # Already dropped 'id' above\n",
    "high_missing_test = ['ps_car_03_cat', 'ps_car_05_cat']\n",
    "\n",
    "X_test_df = X_test_df.drop(columns=cols_to_drop_test, errors='ignore')\n",
    "X_test_df = X_test_df.drop(columns=high_missing_test, errors='ignore')\n",
    "\n",
    "print(f\"‚úì Dropped columns: {cols_to_drop_test + high_missing_test}\")\n",
    "print(f\"Test data shape after dropping: {X_test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0d28f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Missing values handled successfully!\n",
      "Categorical columns: 12, bins columns: 17, Numeric columns: 32\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "# 3Ô∏è‚É£ Apply imputations on training data\n",
    "X_test_df[cat_cols] = cat_imputer.fit_transform(X_test_df[cat_cols])\n",
    "X_test_df[cat_cols_bins] = cat_bins_imputer.fit_transform(X_test_df[cat_cols_bins])\n",
    "X_test_df[num_cols] = num_imputer.fit_transform(X_test_df[num_cols])\n",
    "\n",
    "\n",
    "print(\"‚úÖ Missing values handled successfully!\")\n",
    "print(f\"Categorical columns: {len(cat_cols)}, bins columns: {len(cat_cols_bins)}, Numeric columns: {len(num_cols)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d4537c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126948, 61)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "308cd0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Missing values in final X: 0\n",
      "‚úÖ Final shape: (296209, 220)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# üîπ Encode Categorical Variables\n",
    "# ============================================================================\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 3Ô∏è‚É£ Encode categorical columns\n",
    "#handle_unknown='use_encoded_value', unknown_value=-1\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded_train = pd.DataFrame(\n",
    "    encoder.fit_transform(X[cat_cols]),\n",
    "    columns=encoder.get_feature_names_out(cat_cols),\n",
    "    index=X.index\n",
    ")\n",
    "\n",
    "# 4Ô∏è‚É£ Merge encoded, numeric, binary, and target columns\n",
    "X_train_final = pd.concat(\n",
    "    [encoded_train, X[num_cols], X[cat_cols_bins]],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# üß© Final check\n",
    "print(\"‚úÖ Missing values in final X:\", X_train_final.isnull().sum().sum())\n",
    "print(\"‚úÖ Final shape:\", X_train_final.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7aee7806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Missing values in final X_test_final: 0\n",
      "‚úÖ Final shape: (126948, 220)\n",
      "‚úÖ Final shape: (296209, 220)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# üîπ Encode Categorical Variables\n",
    "# ============================================================================\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 3Ô∏è‚É£ Encode categorical columns\n",
    "\n",
    "encoded_test_df = pd.DataFrame(\n",
    "    encoder.transform(X_test_df[cat_cols]),    # ‚úÖ use transform, not fit_transform\n",
    "    columns=encoder.get_feature_names_out(cat_cols),\n",
    "    index=X_test_df.index\n",
    ")\n",
    "\n",
    "# 4Ô∏è‚É£ Merge encoded, numeric, binary, and target columns\n",
    "X_test_final = pd.concat(\n",
    "    [encoded_test_df, X_test_df[num_cols], X_test_df[cat_cols_bins]],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# üß© Final check\n",
    "print(\"‚úÖ Missing values in final X_test_final:\", X_test_final.isnull().sum().sum())\n",
    "print(\"‚úÖ Final shape:\", X_test_final.shape)\n",
    "print(\"‚úÖ Final shape:\", X_full.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1c674ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî∏ Columns only in train: set()\n",
      "\n",
      "üîπ Columns only in test: set()\n"
     ]
    }
   ],
   "source": [
    "train_cols = set(X_train_final.columns)\n",
    "test_cols = set(X_test_final.columns)\n",
    "\n",
    "print(\"\\nüî∏ Columns only in train:\", train_cols - test_cols)\n",
    "print(\"\\nüîπ Columns only in test:\", test_cols - train_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5040a7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Column counts match!\n"
     ]
    }
   ],
   "source": [
    "if X_test_final.shape[1] != X_full.shape[1]:\n",
    "    print(\"\\n‚ö†Ô∏è WARNING: Column count mismatch!\")\n",
    "    print(f\"Test: {X_test_final.shape[1]}, Train: {X_full.shape[1]}\")\n",
    "else:\n",
    "    print(\"\\n‚úì Column counts match!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9efff428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "APPLYING SCALING...\n",
      "--------------------------------------------------------------------------------\n",
      "‚úì Scaling complete\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"APPLYING SCALING...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "\n",
    "# IMPORTANT: Use transform (not fit_transform) with the scaler fitted on training data\n",
    "X_test_scaled = scaler.transform(X_test_final)\n",
    "\n",
    "print(\"‚úì Scaling complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4ce4a7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Generating predictions using KNN...\n",
      "‚úÖ Saved: submission_KNN.csv | Shape: (126948, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîπ Generating predictions using KNN...\")\n",
    "\n",
    "try:\n",
    "    y_pred_proba = knn_model.predict_proba(X_test_final)[:, 1]\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è KNN predict_proba failed ({e}). Using predict() instead.\")\n",
    "    y_pred_proba = knn_model.predict(X_test_final)\n",
    "\n",
    "submission_knn = pd.DataFrame({\n",
    "    \"id\": test[\"id\"],\n",
    "    \"target\": y_pred_proba\n",
    "})\n",
    "submission_knn.to_csv(\"submission_KNN.csv\", index=False)\n",
    "print(\"‚úÖ Saved: submission_KNN.csv | Shape:\", submission_knn.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5f0d2b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Generating predictions using Decision Tree...\n",
      "‚úÖ Saved: submission_DecisionTree.csv | Shape: (126948, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîπ Generating predictions using Decision Tree...\")\n",
    "\n",
    "try:\n",
    "    y_pred_proba = dt_model.predict_proba(X_test_final)[:, 1]\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Decision Tree predict_proba failed ({e}). Using predict() instead.\")\n",
    "    y_pred_proba = dt_model.predict(X_test_final)\n",
    "\n",
    "submission_dt = pd.DataFrame({\n",
    "    \"id\": test[\"id\"],\n",
    "    \"target\": y_pred_proba\n",
    "})\n",
    "submission_dt.to_csv(\"submission_DecisionTree.csv\", index=False)\n",
    "print(\"‚úÖ Saved: submission_DecisionTree.csv | Shape:\", submission_dt.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d6ff5705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Generating predictions using Random Forest...\n",
      "‚úÖ Saved: submission_RandomForest.csv | Shape: (126948, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîπ Generating predictions using Random Forest...\")\n",
    "\n",
    "try:\n",
    "    y_pred_proba = rf_model.predict_proba(X_test_final)[:, 1]\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Random Forest predict_proba failed ({e}). Using predict() instead.\")\n",
    "    y_pred_proba = rf_model.predict(X_test_final)\n",
    "\n",
    "submission_rf = pd.DataFrame({\n",
    "    \"id\": test[\"id\"],\n",
    "    \"target\": y_pred_proba\n",
    "})\n",
    "submission_rf.to_csv(\"submission_RandomForest.csv\", index=False)\n",
    "print(\"‚úÖ Saved: submission_RandomForest.csv | Shape:\", submission_rf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7c7a2e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Generating predictions using AdaBoost...\n",
      "‚úÖ Saved: submission_AdaBoost.csv | Shape: (126948, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîπ Generating predictions using AdaBoost...\")\n",
    "\n",
    "try:\n",
    "    y_pred_proba = ada_model.predict_proba(X_test_final)[:, 1]\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è AdaBoost predict_proba failed ({e}). Using predict() instead.\")\n",
    "    y_pred_proba = ada_model.predict(X_test_final)\n",
    "\n",
    "submission_ada = pd.DataFrame({\n",
    "    \"id\": test[\"id\"],\n",
    "    \"target\": y_pred_proba\n",
    "})\n",
    "submission_ada.to_csv(\"submission_AdaBoost.csv\", index=False)\n",
    "print(\"‚úÖ Saved: submission_AdaBoost.csv | Shape:\", submission_ada.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "72440e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Sample comparison of predictions:\n",
      "       id  KNN  DecisionTree  RandomForest  AdaBoost\n",
      "0  722071  0.2      0.741781      0.436014  0.282848\n",
      "1  114307  0.0      0.760415      0.421473  0.338923\n",
      "2   17470  0.2      0.546185      0.497358  0.312417\n",
      "3  660658  0.2      0.414098      0.461664  0.265628\n",
      "4  813204  0.0      0.499170      0.389818  0.295837\n"
     ]
    }
   ],
   "source": [
    "sample_preds = pd.DataFrame({\"id\": test[\"id\"].head(5)})\n",
    "sample_preds[\"KNN\"] = submission_knn[\"target\"].head(5)\n",
    "sample_preds[\"DecisionTree\"] = submission_dt[\"target\"].head(5)\n",
    "sample_preds[\"RandomForest\"] = submission_rf[\"target\"].head(5)\n",
    "sample_preds[\"AdaBoost\"] = submission_ada[\"target\"].head(5)\n",
    "\n",
    "print(\"\\nüîç Sample comparison of predictions:\")\n",
    "print(sample_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5ba1b561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SUBMISSION FILES VERIFICATION\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Checking submission files...\n",
      "\n",
      "‚ùå submission_NaiveBayes.csv NOT FOUND!\n",
      "\n",
      "üìÑ submission_KNN.csv\n",
      "   Shape: (126948, 2)\n",
      "   Columns: ['id', 'target']\n",
      "   Target range: [0.0000, 0.8000]\n",
      "   Target mean: 0.0478\n",
      "   Missing values: 0\n",
      "   ‚úÖ All predictions valid\n",
      "\n",
      "üìÑ submission_DecisionTree.csv\n",
      "   Shape: (126948, 2)\n",
      "   Columns: ['id', 'target']\n",
      "   Target range: [0.0000, 0.9811]\n",
      "   Target mean: 0.4552\n",
      "   Missing values: 0\n",
      "   ‚úÖ All predictions valid\n",
      "\n",
      "üìÑ submission_RandomForest.csv\n",
      "   Shape: (126948, 2)\n",
      "   Columns: ['id', 'target']\n",
      "   Target range: [0.1759, 0.6998]\n",
      "   Target mean: 0.3997\n",
      "   Missing values: 0\n",
      "   ‚úÖ All predictions valid\n",
      "\n",
      "üìÑ submission_AdaBoost.csv\n",
      "   Shape: (126948, 2)\n",
      "   Columns: ['id', 'target']\n",
      "   Target range: [0.1665, 0.4154]\n",
      "   Target mean: 0.2655\n",
      "   Missing values: 0\n",
      "   ‚úÖ All predictions valid\n",
      "\n",
      "================================================================================\n",
      "NEXT STEPS\n",
      "================================================================================\n",
      "\n",
      "1. Upload to Kaggle:\n",
      "   https://www.kaggle.com/t/069d1cac492a4be1aa786f50d8c91122\n",
      "\n",
      "2. Recommended submission order:\n",
      "   1Ô∏è‚É£  submission_RandomForest.csv (BEST - submit first)\n",
      "   2Ô∏è‚É£  submission_AdaBoost.csv\n",
      "   3Ô∏è‚É£  submission_DecisionTree.csv\n",
      "   4Ô∏è‚É£  submission_KNN.csv\n",
      "   5Ô∏è‚É£  submission_NaiveBayes.csv\n",
      "\n",
      "3. Record each model's public leaderboard AUROC\n",
      "\n",
      "‚úÖ Good luck!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "VERIFICATION: Check All Submission Files\n",
    "Run this to verify everything is correct\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SUBMISSION FILES VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "submission_files = [\n",
    "    \"submission_NaiveBayes.csv\",\n",
    "    \"submission_KNN.csv\",\n",
    "    \"submission_DecisionTree.csv\",\n",
    "    \"submission_RandomForest.csv\",\n",
    "    \"submission_AdaBoost.csv\"\n",
    "]\n",
    "\n",
    "print(\"\\n‚úÖ Checking submission files...\\n\")\n",
    "\n",
    "for filename in submission_files:\n",
    "    if os.path.exists(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        \n",
    "        print(f\"üìÑ {filename}\")\n",
    "        print(f\"   Shape: {df.shape}\")\n",
    "        print(f\"   Columns: {df.columns.tolist()}\")\n",
    "        print(f\"   Target range: [{df['target'].min():.4f}, {df['target'].max():.4f}]\")\n",
    "        print(f\"   Target mean: {df['target'].mean():.4f}\")\n",
    "        print(f\"   Missing values: {df.isnull().sum().sum()}\")\n",
    "        \n",
    "        # Check for valid probabilities\n",
    "        if (df['target'] < 0).any() or (df['target'] > 1).any():\n",
    "            print(f\"   ‚ö†Ô∏è  WARNING: Some predictions outside [0, 1] range!\")\n",
    "        else:\n",
    "            print(f\"   ‚úÖ All predictions valid\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"‚ùå {filename} NOT FOUND!\\n\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n1. Upload to Kaggle:\")\n",
    "print(\"   https://www.kaggle.com/t/069d1cac492a4be1aa786f50d8c91122\")\n",
    "print(\"\\n2. Recommended submission order:\")\n",
    "print(\"   1Ô∏è‚É£  submission_RandomForest.csv (BEST - submit first)\")\n",
    "print(\"   2Ô∏è‚É£  submission_AdaBoost.csv\")\n",
    "print(\"   3Ô∏è‚É£  submission_DecisionTree.csv\")\n",
    "print(\"   4Ô∏è‚É£  submission_KNN.csv\")\n",
    "print(\"   5Ô∏è‚É£  submission_NaiveBayes.csv\")\n",
    "print(\"\\n3. Record each model's public leaderboard AUROC\")\n",
    "print(\"\\n‚úÖ Good luck!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468b5668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL 6: CATBOOST WITH HYPERPARAMETER TUNING\n",
      "================================================================================\n",
      "Training samples: 296,209\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Starting Grid Search for optimal parameters...\n",
      "--------------------------------------------------------------------------------\n",
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "\n",
      "‚úì Grid Search completed in 45005.36 seconds\n",
      "\n",
      "Best parameters found:\n",
      "  border_count: 32\n",
      "  depth: 6\n",
      "  iterations: 500\n",
      "  l2_leaf_reg: 5\n",
      "  learning_rate: 0.03\n",
      "\n",
      "Best CV AUROC: 0.6383\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Training final model with best parameters...\n",
      "--------------------------------------------------------------------------------\n",
      "‚úì Training completed in 0.00 seconds\n",
      "\n",
      "Model info:\n",
      "  Number of trees: 500\n",
      "  Max depth: 6\n",
      "  Learning rate: 0.03\n",
      "\n",
      "Training set performance:\n",
      "  AUROC: 0.67853545\n",
      "  Accuracy: 0.94818523\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97    281023\n",
      "           1       0.39      0.02      0.04     15186\n",
      "\n",
      "    accuracy                           0.95    296209\n",
      "   macro avg       0.67      0.51      0.51    296209\n",
      "weighted avg       0.92      0.95      0.93    296209\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Top 10 Important Features:\n",
      "  ps_ind_03                     : 9.3370\n",
      "  ps_car_13                     : 7.1361\n",
      "  ps_reg_01                     : 4.9687\n",
      "  ps_ind_15                     : 4.6452\n",
      "  ps_reg_02                     : 3.6249\n",
      "  ps_ind_05_cat_0.0             : 3.5811\n",
      "  ps_ind_17_bin                 : 3.3785\n",
      "  ps_reg_03                     : 3.1532\n",
      "  feature4                      : 2.5495\n",
      "  ps_car_14                     : 2.4677\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Top 5 Parameter Combinations:\n",
      "--------------------------------------------------------------------------------\n",
      "                                                params  mean_test_score  \\\n",
      "42   {'border_count': 32, 'depth': 6, 'iterations':...         0.638336   \n",
      "123  {'border_count': 64, 'depth': 6, 'iterations':...         0.638065   \n",
      "120  {'border_count': 64, 'depth': 6, 'iterations':...         0.637977   \n",
      "204  {'border_count': 128, 'depth': 6, 'iterations'...         0.637920   \n",
      "24   {'border_count': 32, 'depth': 4, 'iterations':...         0.637759   \n",
      "\n",
      "     std_test_score  rank_test_score  \n",
      "42         0.000917                1  \n",
      "123        0.000922                2  \n",
      "120        0.000459                3  \n",
      "204        0.000874                4  \n",
      "24         0.000453                5  \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 179\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_test_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank_test_score\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# Store results\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m \u001b[43mresults\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoost (Tuned)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    180\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain_AUROC\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_auroc_cat)\n\u001b[0;32m    181\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain_Acc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_acc_cat)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL 6: CATBOOST WITH PARAMETER GRID SEARCH\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL 6: CATBOOST WITH HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"Training samples: {X_full.shape[0]:,}\")\n",
    "\n",
    "# ============================================================================\n",
    "# OPTION 1: GRID SEARCH (More thorough but slower)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Starting Grid Search for optimal parameters...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'iterations': [300, 500, 700],\n",
    "    'learning_rate': [0.03, 0.05, 0.1],\n",
    "    'depth': [4, 6, 8],\n",
    "    'l2_leaf_reg': [1, 3, 5],\n",
    "    'border_count': [32, 64, 128]\n",
    "}\n",
    "\n",
    "# Base model\n",
    "base_catboost = CatBoostClassifier(\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    random_seed=RANDOM_STATE,\n",
    "    class_weights=[1, 5],\n",
    "    verbose=False,  # Suppress output during grid search\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "# Grid Search\n",
    "start_time = time.time()\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=base_catboost,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_full, y_full)\n",
    "\n",
    "grid_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úì Grid Search completed in {grid_time:.2f} seconds\")\n",
    "print(f\"\\nBest parameters found:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print(f\"\\nBest CV AUROC: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Use best model\n",
    "catboost_model = grid_search.best_estimator_\n",
    "\n",
    "# ============================================================================\n",
    "# OPTION 2: RANDOMIZED SEARCH (Faster alternative - comment out Option 1 to use)\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Starting Randomized Search for optimal parameters...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Define parameter distributions\n",
    "param_distributions = {\n",
    "    'iterations': [300, 400, 500, 600, 700],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.07, 0.1, 0.15],\n",
    "    'depth': [4, 5, 6, 7, 8, 9, 10],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "    'border_count': [32, 64, 128, 254],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Base model\n",
    "base_catboost = CatBoostClassifier(\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    random_seed=RANDOM_STATE,\n",
    "    class_weights=[1, 5],\n",
    "    verbose=False,\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "# Randomized Search\n",
    "start_time = time.time()\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=base_catboost,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,  # Number of parameter combinations to try\n",
    "    cv=3,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "random_search.fit(X_full, y_full)\n",
    "\n",
    "grid_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úì Randomized Search completed in {grid_time:.2f} seconds\")\n",
    "print(f\"\\nBest parameters found:\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print(f\"\\nBest CV AUROC: {random_search.best_score_:.4f}\")\n",
    "\n",
    "# Use best model\n",
    "catboost_model = random_search.best_estimator_\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# TRAIN FINAL MODEL AND EVALUATE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Training final model with best parameters...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# If you want to retrain on full data with best params\n",
    "# catboost_model.fit(X_full, y_full)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"‚úì Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "print(f\"\\nModel info:\")\n",
    "print(f\"  Number of trees: {catboost_model.tree_count_}\")\n",
    "print(f\"  Max depth: {catboost_model.get_params()['depth']}\")\n",
    "print(f\"  Learning rate: {catboost_model.get_params()['learning_rate']}\")\n",
    "\n",
    "# Training set performance (for reference only)\n",
    "print(\"\\nTraining set performance:\")\n",
    "y_train_pred_cat = catboost_model.predict(X_full)\n",
    "y_train_proba_cat = catboost_model.predict_proba(X_full)[:, 1]\n",
    "\n",
    "train_auroc_cat = roc_auc_score(y_full, y_train_proba_cat)\n",
    "train_acc_cat = accuracy_score(y_full, y_train_pred_cat)\n",
    "\n",
    "print(f\"  AUROC: {train_auroc_cat:.8f}\")\n",
    "print(f\"  Accuracy: {train_acc_cat:.8f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_full, y_train_pred_cat))\n",
    "\n",
    "# Feature importance\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Top 10 Important Features:\")\n",
    "feature_importance_cat = pd.DataFrame({\n",
    "    'Feature': X_full.columns,\n",
    "    'Importance': catboost_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "for i, row in feature_importance_cat.head(10).iterrows():\n",
    "    print(f\"  {row['Feature']:30s}: {row['Importance']:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# DISPLAY GRID SEARCH RESULTS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Top 5 Parameter Combinations:\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "results_df = results_df.sort_values('rank_test_score')\n",
    "print(results_df[['params', 'mean_test_score', 'std_test_score', 'rank_test_score']].head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e34693e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Generating predictions using CatBoost...\n",
      "‚úÖ Saved: submission_CatBoost.csv | Shape: (126948, 2)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# GENERATE CATBOOST TEST PREDICTIONS\n",
    "# ============================================================================\n",
    "print(\"\\nüîπ Generating predictions using CatBoost...\")\n",
    "\n",
    "try:\n",
    "    y_pred_proba = catboost_model.predict_proba(X_test_final)[:, 1]\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è CatBoost predict_proba failed ({e}). Using predict() instead.\")\n",
    "    y_pred_proba = catboost_model.predict(X_test_final)\n",
    "\n",
    "submission_catboost = pd.DataFrame({\n",
    "    \"id\": test[\"id\"],\n",
    "    \"target\": y_pred_proba\n",
    "})\n",
    "submission_catboost.to_csv(\"submission_CatBoost.csv\", index=False)\n",
    "print(\"‚úÖ Saved: submission_CatBoost.csv | Shape:\", submission_catboost.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7cc6db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4393e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
